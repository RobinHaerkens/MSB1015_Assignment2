results.plsr <- cbind(results$bp, allDescs)
colnames(results.plsr)[1] <- 'bp'
NANs <- sapply(results.plsr, function(x) all(is.nan(x)))
results.plsr <- results.plsr[,!NANs]
bp.plsr <- plsr(bp ~. , data=results.plsr, validation = "LOO")
View(results.plsr)
View(results.plsr)
results.plsr <- cbind(results$bp, allDescs)
colnames(results.plsr)[1] <- 'bp'
results.plsr <- results.plsr[,-23]
bp.plsr <- plsr(bp ~. , data=results.plsr, validation = "LOO")
View(results.plsr)
View(results.plsr)
results.plsr <- cbind(results$bp, allDescs)
colnames(results.plsr)[1] <- 'bp'
#results.plsr <- results.plsr[,-23]
bp.plsr <- plsr(bp ~. , data=results.plsr, validation = "LOO")
View(results.plsr)
results.plsr <- cbind(results$bp, allDescs)
colnames(results.plsr)[1] <- 'bp'
results.plsr <- results.plsr[,-26]
results.plsr <- results.plsr[,-23]
bp.plsr <- plsr(bp ~. , data=results.plsr, validation = "LOO")
summary(bp.plsr)
results.plsr <- cbind(results$bp, allDescs)
colnames(results.plsr)[1] <- 'bp'
#removing NAs and NANs
results.plsr[ , -which(names(results.plsr) %in% c("z","u"))]
bp.plsr <- plsr(bp ~. , data=results.plsr, validation = "LOO")
View(results.plsr)
results.plsr <- cbind(results$bp, allDescs)
colnames(results.plsr)[1] <- 'bp'
#removing NAs and NANs
results.plsr[ , -which(names(results.plsr) %in% c(VABC,geomShape))]
results.plsr <- cbind(results$bp, allDescs)
colnames(results.plsr)[1] <- 'bp'
#removing NAs and NANs
results.plsr[ , -which(names(results.plsr) %in% c("VABC","geomShape"))]
bp.plsr <- plsr(bp ~. , data=results.plsr, validation = "LOO")
View(results.plsr)
results.plsr <- cbind(results$bp, allDescs)
colnames(results.plsr)[1] <- 'bp'
#removing NAs and NANs
results.plsr <- results.plsr[ , -which(names(results.plsr) %in% c("VABC","geomShape"))]
bp.plsr <- plsr(bp ~. , data=results.plsr, validation = "LOO")
summary(gas1)
summary(bp.plsr)
results.plsr <- cbind(results$bp, allDescs)
colnames(results.plsr)[1] <- 'bp'
#removing NAs and NANs
results.plsr <- results.plsr[ , -which(names(results.plsr) %in% c("VABC","geomShape"))]
bp.plsr <- plsr(bp ~. , data=results.plsr, validation = "LOO", ncomp=4)
summary(bp.plsr)
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(123)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- mtcars[train_ind, ]
test <- mtcars[-train_ind, ]
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(123)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
if(!"RCy3" %in% installed.packages()){
install.packages("WikidataQueryServiceR")
install.packages("rJava")
install.packages ("rcdk")
install.packages("pls")
}
library(WikidataQueryServiceR)
library(rJava)
library(rcdk)
library(pls)
sparql_query <- 'SELECT DISTINCT ?comp ?compLabel ?bp ?bpUnitLabel ?SMILE WHERE {
?comp wdt:P31/wdt:P279* wd:Q41581 ;
p:P2102 [
ps:P2102 ?bp ;
psv:P2102/wikibase:quantityUnit  ?bpUnit
] ;
wdt:P233 ?SMILE .
SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". }
}'
results = query_wikidata(sparql_query)
results_SMILES <- results[,5]
pattern<- "\\("
replacement <- ""
results[,5] <- gsub(pattern, replacement, results[,5])
pattern<- "\\)"
results[,5] <- gsub(pattern, replacement, results[,5])
plot(results[order(nchar(results[,5])),3], xlab="alkane length", ylab="bp")
for(i in 1:nrow(results)){
if (results[i,4] == "degree Celsius"){
results[i,3] <- results[i,3]+273.15
results[i,4] <- "kelvin"
}
}
for(i in 1:nrow(results)){
if (results[i,4] == "degree Fahrenheit"){
results[i,3] <- ((results[i,3]+ 459.67)*5/9)
results[i,4] <- "kelvin"
}
}
plot(results[order(nchar(results[,5])),3], xlab="alkane length", ylab="bp")
#reassign the orignal SMILES to the results
results[,5] <- results_SMILES
#parse all the alkane smiles through the rcdk package to obtain all availlable information
results.rcdk <- parse.smiles(results[,5])
#select descriptive categories
dc <- get.desc.categories()
#select names of discriptive topological caterogies)
dn <- get.desc.names(dc[3])
allDescs <- eval.desc(results.rcdk, dn)
results.plsr <- cbind(results$bp, allDescs)
colnames(results.plsr)[1] <- 'bp'
#removing NAs and NANs
results.plsr <- results.plsr[ , -which(names(results.plsr) %in% c("VABC","geomShape"))]
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(123)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
?predict
predict(bp.plsr, data=test)
predict <- predict(bp.plsr, data=test)
bp.plsr
summary(bp.plsr)
bp.plsr.test <- plsr(bp ~. , data=test, ncomp=4)
bp.plsr.train <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
summary(bp.plsr.test)
summary(bp.plsr.train)
summary(bp.plsr.test)
summary(bp.plsr.train)
Prediction <- predict(bp.plsr, test[,-(bp)])
Prediction <- predict(bp.plsr, test[,-("bp")])
View(test)
Prediction <- predict(bp.plsr, test[,-(bp)])
?which
bp_index <- which(colnames(test) == "bp")
Prediction <- predict(bp.plsr, test[,])
rmse(test$bp, Prediction)
RMSE(test$bp, Prediction)
RMSEP(test$bp, Prediction)
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, test[,])
bp_index
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test[,-bp_index])
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
Prediction
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(123)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
Prediction <- RMSEP(bp.plsr, newdata=test)
Prediction
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
Prediction
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
Prediction
seed
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(1)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
Prediction
View(results)
index_SMILES <- which(colnames(results)=="SMILE")
index_SMILES
results_SMILES <- results[,index_SMILES]
#get index of colnumbers to make SMILE and bp selection
index_SMILES <- which(colnames(results)=="SMILE")
index_bp <- which(colnames(results) =="bp")
#save the actual SMILES for later use
results_SMILES <- results[,index_SMILES]
#remove "(" and ")" to get a line of just C's
pattern<- "\\("
replacement <- ""
results[,5] <- gsub(pattern, replacement, results[,index_SMILES])
pattern<- "\\)"
results[,5] <- gsub(pattern, replacement, results[,index_SMILES])
#plot the amount of C's against bp to see releation and look for outlayers
plot(results[order(nchar(results[,index_SMILES])),index_bp], xlab="alkane length", ylab="bp")
#get index of colnumbers to make SMILE and bp selection
index_SMILES <- which(colnames(results)=="SMILE")
index_bp <- which(colnames(results) =="bp")
index_bpUnit <- which(colnames(results)=="bpUnitLabel")
#save the actual SMILES for later use
results_SMILES <- results[,index_SMILES]
#remove "(" and ")" to get a line of just C's
pattern<- "\\("
replacement <- ""
results[,5] <- gsub(pattern, replacement, results[,index_SMILES])
pattern<- "\\)"
results[,5] <- gsub(pattern, replacement, results[,index_SMILES])
#plot the amount of C's against bp to see releation and look for outlayers
plot(results[order(nchar(results[,index_SMILES])),index_bp], xlab="alkane length", ylab="bp")
#change Celsius to Kelvin
for(i in 1:nrow(results)){
if (results[i,index_bpUnit] == "degree Celsius"){
results[i,index_bp] <- results[i,index_bp]+273.15
results[i,index_bpUnit] <- "kelvin"
}
}
#Change Fahrenheit to Kelvin
for(i in 1:nrow(results)){
if (results[i,index_bpUnit] == "degree Fahrenheit"){
results[i,index_bp] <- ((results[i,index_bp]+ 459.67)*5/9)
results[i,index_bpUnit] <- "kelvin"
}
}
if(!"RCy3" %in% installed.packages()){
install.packages("WikidataQueryServiceR")
install.packages("rJava")
install.packages ("rcdk")
install.packages("pls")
}
library(WikidataQueryServiceR)
library(rJava)
library(rcdk)
library(pls)
if(!"RCy3" %in% installed.packages()){
install.packages("WikidataQueryServiceR")
install.packages("rJava")
install.packages ("rcdk")
install.packages("pls")
}
library(WikidataQueryServiceR)
library(rJava)
library(rcdk)
library(pls)
sparql_query <- 'SELECT DISTINCT ?comp ?compLabel ?bp ?bpUnitLabel ?SMILE WHERE {
?comp wdt:P31/wdt:P279* wd:Q41581 ;
p:P2102 [
ps:P2102 ?bp ;
psv:P2102/wikibase:quantityUnit  ?bpUnit
] ;
wdt:P233 ?SMILE .
SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". }
}'
results = query_wikidata(sparql_query)
#get index of colnumbers to make SMILE and bp selection
index_SMILES <- which(colnames(results)=="SMILE")
index_bp <- which(colnames(results) =="bp")
index_bpUnit <- which(colnames(results)=="bpUnitLabel")
#save the actual SMILES for later use
results_SMILES <- results[,index_SMILES]
#remove "(" and ")" to get a line of just C's
pattern<- "\\("
replacement <- ""
results[,5] <- gsub(pattern, replacement, results[,index_SMILES])
pattern<- "\\)"
results[,5] <- gsub(pattern, replacement, results[,index_SMILES])
#plot the amount of C's against bp to see releation and look for outlayers
plot(results[order(nchar(results[,index_SMILES])),index_bp], xlab="alkane length", ylab="bp")
#change Celsius to Kelvin
for(i in 1:nrow(results)){
if (results[i,index_bpUnit] == "degree Celsius"){
results[i,index_bp] <- results[i,index_bp]+273.15
results[i,index_bpUnit] <- "kelvin"
}
}
#Change Fahrenheit to Kelvin
for(i in 1:nrow(results)){
if (results[i,index_bpUnit] == "degree Fahrenheit"){
results[i,index_bp] <- ((results[i,index_bp]+ 459.67)*5/9)
results[i,index_bpUnit] <- "kelvin"
}
}
#plot again with all units converted to kelvin
plot(results[order(nchar(results[,index_SMILES])),index_bp], xlab="alkane length", ylab="bp")
#reassign the orignal SMILES to the results
results[,index_SMILES] <- results_SMILES
#parse all the alkane smiles through the rcdk package to obtain all availlable information
results.rcdk <- parse.smiles(results[,index_SMILES])
#select descriptive categories
dc <- get.desc.categories()
#select names of discriptive topological caterogies)
dn <- get.desc.names(dc[3])
allDescs <- eval.desc(results.rcdk, dn)
#create a df with bp and all features to use for plsr model
results.plsr <- cbind(results$bp, allDescs)
colnames(results.plsr)[1] <- 'bp'
#removing NAs and NANs
results.plsr <- results.plsr[ , -which(names(results.plsr) %in% c("VABC","geomShape"))]
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(1)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 54.87 at time of running
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(1)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 54.87 at time of running
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(2)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 54.87 at time of running
if(!"RCy3" %in% installed.packages()){
install.packages("WikidataQueryServiceR")
install.packages("rJava")
install.packages ("rcdk")
install.packages("pls")
}
library(WikidataQueryServiceR)
library(rJava)
library(rcdk)
library(pls)
sparql_query <- 'SELECT DISTINCT ?comp ?compLabel ?bp ?bpUnitLabel ?SMILE WHERE {
?comp wdt:P31/wdt:P279* wd:Q41581 ;
p:P2102 [
ps:P2102 ?bp ;
psv:P2102/wikibase:quantityUnit  ?bpUnit
] ;
wdt:P233 ?SMILE .
SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". }
}'
results = query_wikidata(sparql_query)
#get index of colnumbers to make SMILE and bp selection
index_SMILES <- which(colnames(results)=="SMILE")
index_bp <- which(colnames(results) =="bp")
index_bpUnit <- which(colnames(results)=="bpUnitLabel")
#save the actual SMILES for later use
results_SMILES <- results[,index_SMILES]
#remove "(" and ")" to get a line of just C's
pattern<- "\\("
replacement <- ""
results[,5] <- gsub(pattern, replacement, results[,index_SMILES])
pattern<- "\\)"
results[,5] <- gsub(pattern, replacement, results[,index_SMILES])
#plot the amount of C's against bp to see releation and look for outlayers
plot(results[order(nchar(results[,index_SMILES])),index_bp], xlab="alkane length", ylab="bp")
#change Celsius to Kelvin
for(i in 1:nrow(results)){
if (results[i,index_bpUnit] == "degree Celsius"){
results[i,index_bp] <- results[i,index_bp]+273.15
results[i,index_bpUnit] <- "kelvin"
}
}
#Change Fahrenheit to Kelvin
for(i in 1:nrow(results)){
if (results[i,index_bpUnit] == "degree Fahrenheit"){
results[i,index_bp] <- ((results[i,index_bp]+ 459.67)*5/9)
results[i,index_bpUnit] <- "kelvin"
}
}
#plot again with all units converted to kelvin
plot(results[order(nchar(results[,index_SMILES])),index_bp], xlab="alkane length", ylab="bp")
#reassign the orignal SMILES to the results
results[,index_SMILES] <- results_SMILES
#parse all the alkane smiles through the rcdk package to obtain all availlable information
results.rcdk <- parse.smiles(results[,index_SMILES])
#select descriptive categories
dc <- get.desc.categories()
#select names of discriptive topological caterogies)
dn <- get.desc.names(dc[3])
allDescs <- eval.desc(results.rcdk, dn)
#create a df with bp and all features to use for plsr model
results.plsr <- cbind(results$bp, allDescs)
colnames(results.plsr)[1] <- 'bp'
#removing NAs and NANs
results.plsr <- results.plsr[ , -which(names(results.plsr) %in% c("VABC","geomShape"))]
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(2)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 17.4 at time of running
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(3)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 17.4 at time of running
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(1)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 17.4 at time of running
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(123)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 17.4 at time of running
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(3)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 17.4 at time of running
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(123)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 17.4 at time of running
