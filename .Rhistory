results[i,index_bp] <- results[i,index_bp]+273.15
results[i,index_bpUnit] <- "kelvin"
}
}
#Change Fahrenheit to Kelvin
for(i in 1:nrow(results)){
if (results[i,index_bpUnit] == "degree Fahrenheit"){
results[i,index_bp] <- ((results[i,index_bp]+ 459.67)*5/9)
results[i,index_bpUnit] <- "kelvin"
}
}
if(!"RCy3" %in% installed.packages()){
install.packages("WikidataQueryServiceR")
install.packages("rJava")
install.packages ("rcdk")
install.packages("pls")
}
library(WikidataQueryServiceR)
library(rJava)
library(rcdk)
library(pls)
if(!"RCy3" %in% installed.packages()){
install.packages("WikidataQueryServiceR")
install.packages("rJava")
install.packages ("rcdk")
install.packages("pls")
}
library(WikidataQueryServiceR)
library(rJava)
library(rcdk)
library(pls)
sparql_query <- 'SELECT DISTINCT ?comp ?compLabel ?bp ?bpUnitLabel ?SMILE WHERE {
?comp wdt:P31/wdt:P279* wd:Q41581 ;
p:P2102 [
ps:P2102 ?bp ;
psv:P2102/wikibase:quantityUnit  ?bpUnit
] ;
wdt:P233 ?SMILE .
SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". }
}'
results = query_wikidata(sparql_query)
#get index of colnumbers to make SMILE and bp selection
index_SMILES <- which(colnames(results)=="SMILE")
index_bp <- which(colnames(results) =="bp")
index_bpUnit <- which(colnames(results)=="bpUnitLabel")
#save the actual SMILES for later use
results_SMILES <- results[,index_SMILES]
#remove "(" and ")" to get a line of just C's
pattern<- "\\("
replacement <- ""
results[,5] <- gsub(pattern, replacement, results[,index_SMILES])
pattern<- "\\)"
results[,5] <- gsub(pattern, replacement, results[,index_SMILES])
#plot the amount of C's against bp to see releation and look for outlayers
plot(results[order(nchar(results[,index_SMILES])),index_bp], xlab="alkane length", ylab="bp")
#change Celsius to Kelvin
for(i in 1:nrow(results)){
if (results[i,index_bpUnit] == "degree Celsius"){
results[i,index_bp] <- results[i,index_bp]+273.15
results[i,index_bpUnit] <- "kelvin"
}
}
#Change Fahrenheit to Kelvin
for(i in 1:nrow(results)){
if (results[i,index_bpUnit] == "degree Fahrenheit"){
results[i,index_bp] <- ((results[i,index_bp]+ 459.67)*5/9)
results[i,index_bpUnit] <- "kelvin"
}
}
#plot again with all units converted to kelvin
plot(results[order(nchar(results[,index_SMILES])),index_bp], xlab="alkane length", ylab="bp")
#reassign the orignal SMILES to the results
results[,index_SMILES] <- results_SMILES
#parse all the alkane smiles through the rcdk package to obtain all availlable information
results.rcdk <- parse.smiles(results[,index_SMILES])
#select descriptive categories
dc <- get.desc.categories()
#select names of discriptive topological caterogies)
dn <- get.desc.names(dc[3])
allDescs <- eval.desc(results.rcdk, dn)
#create a df with bp and all features to use for plsr model
results.plsr <- cbind(results$bp, allDescs)
colnames(results.plsr)[1] <- 'bp'
#removing NAs and NANs
results.plsr <- results.plsr[ , -which(names(results.plsr) %in% c("VABC","geomShape"))]
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(1)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 54.87 at time of running
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(1)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 54.87 at time of running
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(2)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 54.87 at time of running
if(!"RCy3" %in% installed.packages()){
install.packages("WikidataQueryServiceR")
install.packages("rJava")
install.packages ("rcdk")
install.packages("pls")
}
library(WikidataQueryServiceR)
library(rJava)
library(rcdk)
library(pls)
sparql_query <- 'SELECT DISTINCT ?comp ?compLabel ?bp ?bpUnitLabel ?SMILE WHERE {
?comp wdt:P31/wdt:P279* wd:Q41581 ;
p:P2102 [
ps:P2102 ?bp ;
psv:P2102/wikibase:quantityUnit  ?bpUnit
] ;
wdt:P233 ?SMILE .
SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". }
}'
results = query_wikidata(sparql_query)
#get index of colnumbers to make SMILE and bp selection
index_SMILES <- which(colnames(results)=="SMILE")
index_bp <- which(colnames(results) =="bp")
index_bpUnit <- which(colnames(results)=="bpUnitLabel")
#save the actual SMILES for later use
results_SMILES <- results[,index_SMILES]
#remove "(" and ")" to get a line of just C's
pattern<- "\\("
replacement <- ""
results[,5] <- gsub(pattern, replacement, results[,index_SMILES])
pattern<- "\\)"
results[,5] <- gsub(pattern, replacement, results[,index_SMILES])
#plot the amount of C's against bp to see releation and look for outlayers
plot(results[order(nchar(results[,index_SMILES])),index_bp], xlab="alkane length", ylab="bp")
#change Celsius to Kelvin
for(i in 1:nrow(results)){
if (results[i,index_bpUnit] == "degree Celsius"){
results[i,index_bp] <- results[i,index_bp]+273.15
results[i,index_bpUnit] <- "kelvin"
}
}
#Change Fahrenheit to Kelvin
for(i in 1:nrow(results)){
if (results[i,index_bpUnit] == "degree Fahrenheit"){
results[i,index_bp] <- ((results[i,index_bp]+ 459.67)*5/9)
results[i,index_bpUnit] <- "kelvin"
}
}
#plot again with all units converted to kelvin
plot(results[order(nchar(results[,index_SMILES])),index_bp], xlab="alkane length", ylab="bp")
#reassign the orignal SMILES to the results
results[,index_SMILES] <- results_SMILES
#parse all the alkane smiles through the rcdk package to obtain all availlable information
results.rcdk <- parse.smiles(results[,index_SMILES])
#select descriptive categories
dc <- get.desc.categories()
#select names of discriptive topological caterogies)
dn <- get.desc.names(dc[3])
allDescs <- eval.desc(results.rcdk, dn)
#create a df with bp and all features to use for plsr model
results.plsr <- cbind(results$bp, allDescs)
colnames(results.plsr)[1] <- 'bp'
#removing NAs and NANs
results.plsr <- results.plsr[ , -which(names(results.plsr) %in% c("VABC","geomShape"))]
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(2)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 17.4 at time of running
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(3)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 17.4 at time of running
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(1)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 17.4 at time of running
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(123)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 17.4 at time of running
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(3)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 17.4 at time of running
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(123)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 17.4 at time of running
if(!"RCy3" %in% installed.packages()){
install.packages("WikidataQueryServiceR")
install.packages("rJava")
install.packages ("rcdk")
install.packages("pls")
}
library(WikidataQueryServiceR)
library(rJava)
library(rcdk)
library(pls)
sparql_query <- 'SELECT DISTINCT ?comp ?compLabel ?bp ?bpUnitLabel ?SMILE WHERE {
?comp wdt:P31/wdt:P279* wd:Q41581 ;
p:P2102 [
ps:P2102 ?bp ;
psv:P2102/wikibase:quantityUnit  ?bpUnit
] ;
wdt:P233 ?SMILE .
SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". }
}'
results = query_wikidata(sparql_query)
#get index of colnumbers to make SMILE and bp selection
index_SMILES <- which(colnames(results)=="SMILE")
index_bp <- which(colnames(results) =="bp")
index_bpUnit <- which(colnames(results)=="bpUnitLabel")
#save the actual SMILES for later use
results_SMILES <- results[,index_SMILES]
#remove "(" and ")" to get a line of just C's
pattern<- "\\("
replacement <- ""
results[,5] <- gsub(pattern, replacement, results[,index_SMILES])
pattern<- "\\)"
results[,5] <- gsub(pattern, replacement, results[,index_SMILES])
#plot the amount of C's against bp to see releation and look for outlayers
plot(results[order(nchar(results[,index_SMILES])),index_bp], xlab="alkane length", ylab="bp")
#change Celsius to Kelvin
for(i in 1:nrow(results)){
if (results[i,index_bpUnit] == "degree Celsius"){
results[i,index_bp] <- results[i,index_bp]+273.15
results[i,index_bpUnit] <- "kelvin"
}
}
#Change Fahrenheit to Kelvin
for(i in 1:nrow(results)){
if (results[i,index_bpUnit] == "degree Fahrenheit"){
results[i,index_bp] <- ((results[i,index_bp]+ 459.67)*5/9)
results[i,index_bpUnit] <- "kelvin"
}
}
#plot again with all units converted to kelvin
plot(results[order(nchar(results[,index_SMILES])),index_bp], xlab="alkane length", ylab="bp")
#reassign the orignal SMILES to the results
results[,index_SMILES] <- results_SMILES
#parse all the alkane smiles through the rcdk package to obtain all availlable information
results.rcdk <- parse.smiles(results[,index_SMILES])
#select descriptive categories
dc <- get.desc.categories()
#select names of discriptive topological caterogies)
dn <- get.desc.names(dc[3])
allDescs <- eval.desc(results.rcdk, dn)
#create a df with bp and all features to use for plsr model
results.plsr <- cbind(results$bp, allDescs)
colnames(results.plsr)[1] <- 'bp'
#removing NAs and NANs
results.plsr <- results.plsr[ , -which(names(results.plsr) %in% c("VABC","geomShape"))]
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(123)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 46.8 at time of running
plot(Prediction)
points()
View(results)
plot(Prediction)
points(results$bp)
plot(bp.plsr)
points(results$bp)
plot(results$bp)
#points()
plot()
results$bp
Prediction
bp.plsr
test
bp.plsr$validation$pred
plot(bp.plsr$validation$pred)
points(results$bp)
plot(bp.plsr$validation$pred, results$bp)
plot(bp.plsr$validation$pred, test$bp)
length(bp.plsr$validation$pred)
bp.plsr$validation$pred)
bp.plsr$validation$pred
length(bp.plsr$validation$pred)
predplot(bp.plsr)
predplot(bp.plsr)
if(!"RCy3" %in% installed.packages()){
install.packages("WikidataQueryServiceR")
install.packages("rJava")
install.packages ("rcdk")
install.packages("pls")
}
library(WikidataQueryServiceR)
library(rJava)
library(rcdk)
library(pls)
sparql_query <- 'SELECT DISTINCT ?comp ?compLabel ?bp ?bpUnitLabel ?SMILE WHERE {
?comp wdt:P31/wdt:P279* wd:Q41581 ;
p:P2102 [
ps:P2102 ?bp ;
psv:P2102/wikibase:quantityUnit  ?bpUnit
] ;
wdt:P233 ?SMILE .
SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". }
}'
results = query_wikidata(sparql_query)
#get index of colnumbers to make SMILE and bp selection
index_SMILES <- which(colnames(results)=="SMILE")
index_bp <- which(colnames(results) =="bp")
index_bpUnit <- which(colnames(results)=="bpUnitLabel")
#save the actual SMILES for later use
results_SMILES <- results[,index_SMILES]
#remove "(" and ")" to get a line of just C's
pattern<- "\\("
replacement <- ""
results[,5] <- gsub(pattern, replacement, results[,index_SMILES])
pattern<- "\\)"
results[,5] <- gsub(pattern, replacement, results[,index_SMILES])
#plot the amount of C's against bp to see releation and look for outlayers
plot(results[order(nchar(results[,index_SMILES])),index_bp], xlab="alkane length", ylab="bp")
#change Celsius to Kelvin
for(i in 1:nrow(results)){
if (results[i,index_bpUnit] == "degree Celsius"){
results[i,index_bp] <- results[i,index_bp]+273.15
results[i,index_bpUnit] <- "kelvin"
}
}
#Change Fahrenheit to Kelvin
for(i in 1:nrow(results)){
if (results[i,index_bpUnit] == "degree Fahrenheit"){
results[i,index_bp] <- ((results[i,index_bp]+ 459.67)*5/9)
results[i,index_bpUnit] <- "kelvin"
}
}
#plot again with all units converted to kelvin
plot(results[order(nchar(results[,index_SMILES])),index_bp], xlab="alkane length", ylab="bp")
#reassign the orignal SMILES to the results
results[,index_SMILES] <- results_SMILES
#parse all the alkane smiles through the rcdk package to obtain all availlable information
results.rcdk <- parse.smiles(results[,index_SMILES])
#select descriptive categories
dc <- get.desc.categories()
#select names of discriptive topological caterogies)
dn <- get.desc.names(dc[3])
allDescs <- eval.desc(results.rcdk, dn)
#create a df with bp and all features to use for plsr model
results.plsr <- cbind(results$bp, allDescs)
colnames(results.plsr)[1] <- 'bp'
#removing NAs and NANs
results.plsr <- results.plsr[ , -which(names(results.plsr) %in% c("VABC","geomShape"))]
## 80% of the dataset size
smp_size <- floor(.80 * nrow(results.plsr))
## set the seed to get the same test and training sets when rerunning the code
set.seed(123)
train_ind <- sample(seq_len(nrow(results.plsr)), size = smp_size)
train <- results.plsr[train_ind, ]
test <- results.plsr[-train_ind, ]
bp.plsr <- plsr(bp ~. , data=train, validation = "LOO", ncomp=4)
#select column containing bp
bp_index <- which(colnames(test) == "bp")
Prediction <- RMSEP(bp.plsr, newdata=test)
#compare predicted bp's to actual bp's and look at the RMSEP
Prediction
#RMSEP is 46.8 at time of running
predplot(bp.plsr)
#plot the predicted values against the measured values for the corss-validated values
predplot(bp.plsr)
abline()
#it seems that the model underestimates most of the boiling points a litte bit
#plot the predicted values against the measured values for the corss-validated values
predplot(bp.plsr)
abline(x)
abline
?abline
#plot the predicted values against the measured values for the corss-validated values
predplot(bp.plsr)
abline(a = 0, b = 1)
#it seems that the model underestimates most of the boiling points a litte bit
#plot the predicted values against the measured values for the corss-validated values
predplot(bp.plsr, head = "Predicted bp vs measured Bp of Cross-Validation")
abline(a = 0, b = 1)
#it seems that the model predicts most of the boiling points pretty well except for the lower boiling points
#plot the predicted values against the measured values for the corss-validated values
predplot(bp.plsr, header = "Predicted bp vs measured Bp of Cross-Validation")
abline(a = 0, b = 1)
#it seems that the model predicts most of the boiling points pretty well except for the lower boiling points
#plot the predicted values against the measured values for the corss-validated values
predplot(bp.plsr, title = "Predicted bp vs measured Bp of Cross-Validation")
abline(a = 0, b = 1)
#it seems that the model predicts most of the boiling points pretty well except for the lower boiling points
?predplot
#plot the predicted values against the measured values for the corss-validated values
predplot(bp.plsr, main = "Predicted bp vs measured Bp of Cross-Validation")
abline(a = 0, b = 1)
#it seems that the model predicts most of the boiling points pretty well except for the lower boiling points
Prediction
predplot(bp.plsr ,newdata="test")
predplot(bp.plsr ,newdata=test)
abline(a=0, b=1)
#plot the predicted values against the measured values for the corss-validated values
predplot(bp.plsr, main = "Predicted bp vs measured Bp of Cross-Validation")
abline(a = 0, b = 1)
#it seems that the model predicts most of the boiling points pretty well except for the lower boiling points
#plotting the boiling points of the test set vs the predicted boiling points calculated by the pls model
predplot(bp.plsr, newdata=test, main = "Predicted bp vs measured bp of Test data")
abline(a = 0, b = 1)
#plot the predicted values against the measured values for the corss-validated values
predplot(bp.plsr, main = "Predicted bp vs measured Bp of Cross-Validation")
abline(a = 0, b = 1)
#it seems that the model predicts most of the boiling points pretty well except for the lower boiling points
#plotting the boiling points of the test set vs the predicted boiling points calculated by the pls model
predplot(bp.plsr, newdata=test, main = "Predicted bp vs measured bp of Test data")
abline(a = 0, b = 1)
install.packages("rmarkdown")
library("rmarkdown")
rmarkdown::render_site()
rmarkdown::render_site()
rmarkdown::render_site()
rmarkdown::render_site()
rmarkdown::render_site()
